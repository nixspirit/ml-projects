{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nearest neighbours classification\n",
    "## Model Answers\n",
    " \n",
    "**Task 1:**\n",
    "Run the cell below to load our data. Notice the last line, where we add some random Gaussian noise to our data to make the task more challenging (data in real life usually contains some form of noise).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T14:56:40.665907800Z",
     "start_time": "2023-12-09T14:56:38.959345600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "#view a description of the dataset \n",
    "print(iris.DESCR)\n",
    "\n",
    "#Set X a samples times features matrix, Y equal to the targets\n",
    "X=iris.data \n",
    "y=iris.target \n",
    "\n",
    "\n",
    "#we add some random noise to our data to make the task more challenging\n",
    "X=X+np.random.normal(0,0.4,X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2:**\n",
    "1.\tHow many data samples do we have?\n",
    "2.\tPrint the value below using shape on ```X``` appropriately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T14:56:40.687272600Z",
     "start_time": "2023-12-09T14:56:40.672673400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "#Enter code here\n",
    "print(X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3:**\n",
    "1.\tHow many features do we have?\n",
    "2.\tPrint the value below using shape on ```X``` appropriately. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T14:56:40.688562200Z",
     "start_time": "2023-12-09T14:56:40.681408800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "#Enter code here\n",
    "print(X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4:**\n",
    "1.\tHow many classes do we have?\n",
    "2.\tPrint the value below using ```np.unique``` appropriately. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T14:56:40.792543400Z",
     "start_time": "2023-12-09T14:56:40.689664100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "#Enter code here\n",
    "print(np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5:**\n",
    "1.\tHow many samples do we have that belong to class 1?\n",
    "2.\tPrint this in the cell below using the ```np.where``` function appropriately. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T14:56:40.793666Z",
     "start_time": "2023-12-09T14:56:40.699512500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "50"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Enter code here\n",
    "len(np.where(y==1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6:** \n",
    "\n",
    "Assume we want to generate a list of shuffled indices of our data. Use the function ```numpy.random.permutation``` to do that. In the cell below, you can already see how to create a list of indices that is not shuffled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T14:56:40.794776800Z",
     "start_time": "2023-12-09T14:56:40.727188800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149]\n",
      "[ 48 138  39  15  78  74 126 100  77  64  55 101  85  56  71 137 102 132\n",
      "  47 117 113  20  90 130  22 106 127  54 140 111  91  35 103   8 139 125\n",
      "  52   9  36 145  27  14  59  33  94  43 149  34  32  99  30 109 110  82\n",
      "  58  49  97  73  63  51 118  81   4 105 121  19   0  44  40 119 112  31\n",
      "  72  96  68 142  89   5  70  41  50  26 141  60  45 114  37  67 134 146\n",
      "  79  16  42 104 120 128   2  66  11 115  28  18 143  75  24   7  86 116\n",
      " 133  76  17 124  38   3  13  12  53 108  88   1 144  83  93  69 136  46\n",
      "   6 129  10 123  25  61  62  80 148 122 147  95  87  65  29 135  23 107\n",
      "  92  57  84  21  98 131]\n"
     ]
    }
   ],
   "source": [
    "L=list(range(X.shape[0]))\n",
    "print(L)\n",
    "#Enter code here\n",
    "print(np.random.permutation(L))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 7:**\n",
    "Here is an example of using the k-NN classifier. We split our data to training and testing (with a 0.2 percentage for our test data), fit on the training data, test on the testing data. \n",
    "Go through the code and make sure you understand it.\n",
    "Now do the same for the next cell, which prints the confusion matrix and the total accuracy. \n",
    "You can find some documentation to help you here: http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html. \n",
    "Note that for this lab, we use the Euclidean distance along with 10 neighbours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T14:56:40.942816900Z",
     "start_time": "2023-12-09T14:56:40.732772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 0 0 0 2 0 2 0 1 1 0 2 1 0 1 2 1 0 2 0 2 0 1 0 1 2 2 1]\n",
      "[2 2 0 0 0 0 2 0 2 0 1 1 0 1 1 0 1 2 1 0 2 0 2 0 1 0 1 2 2 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#split to train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "#define knn classifier, with 5 neighbors and use the euclidian distance\n",
    "knn=KNeighborsClassifier(n_neighbors=10, metric='euclidean')\n",
    "#define training and testing data, fit the classifier\n",
    "knn.fit(X_train,y_train)\n",
    "#predict values for test data based on training data\n",
    "y_pred=knn.predict(X_test)\n",
    "#print values\n",
    "print(y_test) # true values\n",
    "print(y_pred) # predicted values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T14:56:40.945011400Z",
     "start_time": "2023-12-09T14:56:40.930402800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  0  0]\n",
      " [ 0  8  0]\n",
      " [ 0  1  9]]\n",
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 8:**\n",
    "Write your <b>own</b> functions that return the confusion matrix given the true and predicted labels, as well as the accuracy. To do so, fill in the code in the next two cells. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T14:56:41.891535400Z",
     "start_time": "2023-12-09T14:56:40.948126700Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 13\u001B[0m\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m C\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m#note: len(np.unique(y))  indicates the dimensions of the confusion matrix (why?)\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m \u001B[38;5;28mprint\u001B[39m(myConfMat(y_test,y_pred,\u001B[38;5;28mlen\u001B[39m(np\u001B[38;5;241m.\u001B[39munique(y))))\n",
      "Cell \u001B[1;32mIn[9], line 6\u001B[0m, in \u001B[0;36mmyConfMat\u001B[1;34m(y_ground, y_pred, classno)\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmyConfMat\u001B[39m(y_ground,y_pred,classno):\n\u001B[1;32m----> 6\u001B[0m     C\u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((classno,classno),dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mint)\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m,\u001B[38;5;28mlen\u001B[39m(y_test)):\n\u001B[0;32m      8\u001B[0m             \u001B[38;5;66;03m#complete this line - assign the appropriate value to C[i,j]\u001B[39;00m\n\u001B[0;32m      9\u001B[0m             C[y_ground[i],y_pred[i]]\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32mD:\\Users\\Slava\\anaconda3\\Lib\\site-packages\\numpy\\__init__.py:305\u001B[0m, in \u001B[0;36m__getattr__\u001B[1;34m(attr)\u001B[0m\n\u001B[0;32m    300\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    301\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIn the future `np.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` will be defined as the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    302\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcorresponding NumPy scalar.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;167;01mFutureWarning\u001B[39;00m, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m    304\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attr \u001B[38;5;129;01min\u001B[39;00m __former_attrs__:\n\u001B[1;32m--> 305\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(__former_attrs__[attr])\n\u001B[0;32m    307\u001B[0m \u001B[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001B[39;00m\n\u001B[0;32m    308\u001B[0m \u001B[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001B[39;00m\n\u001B[0;32m    309\u001B[0m \u001B[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001B[39;00m\n\u001B[0;32m    310\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m    311\u001B[0m \u001B[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001B[39;00m\n\u001B[0;32m    312\u001B[0m \u001B[38;5;66;03m# the full `numpy.testing` namespace\u001B[39;00m\n\u001B[0;32m    313\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attr \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtesting\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "# model answer\n",
    "\n",
    "#create a matrix with entries equal to zero, and subsequently build the confusion matrix\n",
    "#the method should return the confusion matrix in a numpy array\n",
    "def myConfMat(y_ground,y_pred,classno):\n",
    "    C= np.zeros((classno,classno),dtype=np.int)\n",
    "    for i in range(0,len(y_test)):\n",
    "            #complete this line - assign the appropriate value to C[i,j]\n",
    "            C[y_ground[i],y_pred[i]]+=1\n",
    "    return C\n",
    "\n",
    "#note: len(np.unique(y))  indicates the dimensions of the confusion matrix (why?)\n",
    "print(myConfMat(y_test,y_pred,len(np.unique(y))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-09T14:56:41.895896400Z"
    }
   },
   "outputs": [],
   "source": [
    "# model answers\n",
    "\n",
    "#use the numpy function where to return the accuracy given the true/predicted labels.  i.e., #correct/#total\n",
    "def myAccuracy(y_ground,y_pred):\n",
    "    \n",
    "    correct = np.where(y_ground==y_pred, 1, 0 )\n",
    "    total = len(y_ground)\n",
    "    \n",
    "    return sum(correct)/total\n",
    "    \n",
    "# print the accuracy (as a float to two decimal points)\n",
    "print('accuracy: %.2f' % myAccuracy(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional task:**</span> Write your own functions to calculate class-relative precision and recall. Compare these to the sklearn functions ``precision_score`` and ``recall_score`` on your y_test and y_pred values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T14:56:41.908323100Z",
     "start_time": "2023-12-09T14:56:41.900503300Z"
    }
   },
   "outputs": [],
   "source": [
    "#hint: you can use the output from your myConfMat function above\n",
    "\n",
    "def myPrecision(y_ground,y_pred):\n",
    "    classes = np.unique(y_ground)\n",
    "    precision = np.zeros(classes.shape) \n",
    "    \n",
    "    C = myConfMat(y_test,y_pred,len(classes))\n",
    "              \n",
    "    for i in classes:\n",
    "        precision[i] = C[i,i] / sum(C[:,i])\n",
    "        \n",
    "    return precision\n",
    "\n",
    "\n",
    "def myRecall(y_test,y_pred):\n",
    "    classes = np.unique(y_pred)\n",
    "    recall = np.zeros(classes.shape) \n",
    "    \n",
    "    C = myConfMat(y_test,y_pred,len(classes))\n",
    "              \n",
    "    for i in classes:\n",
    "        recall[i] = C[i,i] / sum(C[i,:])\n",
    "    \n",
    "    return recall\n",
    "\n",
    "print('classes:      %s' % np.unique(y_pred) )    \n",
    "print('my precision: %s' % myPrecision(y_test,y_pred))\n",
    "print('my recall:    %s' % myRecall(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-09T14:56:41.902789500Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score \n",
    "# now check that your functions do the same thing as the library versions\n",
    "\n",
    "print('library precision: %s' % precision_score(y_test,y_pred,average=None))\n",
    "print('library recall: %s' % recall_score(y_test,y_pred,average=None))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
